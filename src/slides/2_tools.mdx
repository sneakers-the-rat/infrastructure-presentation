import { Heading, Box, Text, Image, Grid } from 'spectacle'
import Paper from '@material-ui/core/Paper'
import CanvasDraw from "react-canvas-draw";
import VerticalLinearStepper from '../components/vertical_stepper'
import ExptRequirements from '../img/task_requirements_2.png'
import Parallax from '../img/plax.png'
import Overview from '../img/overview.svg'
import anime from 'animejs'
import SvgAnimator from '../components/svg_animator';
import {PositionedHeading, Collapser} from '../components/basic';



<SvgAnimator
    svgUrl={Overview}
    steps={[
      [
        {targets:'#rect-data',
          fill:["#2f0987", "#333333"],
        easing:"easeInOutQuad",
        duration: 500},
        {targets:"#overview-1 #data *",
          stroke: ["#2f0987", "#333333"],
          easing:"easeInOutQuad"
        },
        {targets:'#rect-tools',
          width:[0,750]},
        {targets:"#overview-1 #tools *",
          strokeDashoffset: [anime.setDashoffset, 0]
        },
        {targets:'#rect-knowledge',
          opacity:[0,0]},
        {targets:"#overview-1 #knowledge *",
          opacity: [0,0]
        }
      ]
    ]}
    id={'overview-1'}
/>


<PositionedHeading id={'overview-knowledge'} y={250} x={20}>Knowledge</PositionedHeading>

<PositionedHeading id={'overview-tools'} y={600} x={20}>Tools</PositionedHeading>

<PositionedHeading id={'overview-data'} y={950} x={20}>Data</PositionedHeading>


---

# Analysis tools

* Most widely used tools are either atomic level packages like pandas or dplyr
* Open source packages each with their own parameterization style & difficulty of use, etc
* Many papers don't ever get implementations

We need something that's

<Box >
  <VerticalLinearStepper
      steps={[
        {
          title: 'Modular',
          body: 'Rather than implementing an entire analysis pipeline as a monolith, the system should be broken into minimal, composable modules. The threshold of what constitutes “minimal” is of course to some degree a matter of taste, but the overriding design principle should be to minimize the amount of duplicated labor. Rather than implementing a “peri-stimulus time-histogram” module, we should implement a “binning” module for counting spikes, connect it to an “alignment” module that splits the recording into chunks aligned at the stimulus onset, and so on. Higher-order analysis methods are relatively trivially composed from component parts, but extracting component parts from a frankenstein do-everything script is not. I expect this point to be relatively uncontroversial as it is a general principle of program design',
        },
        {
          title: 'Deployable',
          body:
              'For wide use, the framework needs to be easy to install and deploy locally and on computing clusters. The primary obstacle is dependency management, or making sure that the computer has everything needed to run the program. Anecdotally, more than the complexity of using the package itself, the primary barrier for nonprogrammer scientists using a particular software package is managing to get it installed. Luckily containerization and package management is a widespread and increasingly streamlined practice, so I expect this too to be uncontroversial',
        },
        {
          title: 'Pluggable',
          body:
              'The framework needs to provide a clear way of incorporating external analysis packages, handling their dependencies, and exposing their parameters to the user',
        },
        {
          title: 'Reproducible',
          body:
              "The framework should separate the parameterization of a pipeline, the specific options set by the user, and its implementation, the code that constitutes it. Implicit in a modularly constructed analysis framework is the notion of a “pipeline,” or a specification of a tree (or, specifically, a DAG) of successive stages that process, merge, or split the data from the previous stage. The parameterization of a pipeline should be portable such that it, for example, can be published in the supplementary materials of a paper and reproduced exactly by anyone using the system.",
        },
        {
          title: 'Discoverable',
          body:
              "Two kinds: findable by people who know what they're looking for (and what \
          they're looking for is your data, of course!), ie. searchable, and also as part \
          of a structured knowledge repository among other data of its type. More on this \
          in the federated p2p section...",
        },
      ]}
  />
</Box>

---

# BIDS Apps

Thankfully there are some examples of this

Bids apps - https://bids-apps.neuroimaging.io/tutorial/

Notes: dont render
<Box width={"80%"} height={"80%"} margin={"auto"}>
  <Paper elevation={1} style={{width:"100%", height:"100%"}}>
    <iframe width={"100%"} height={"100%"} loading={"lazy"}
            src={"https://bids-apps.neuroimaging.io/apps/"}
    />
  </Paper>
</Box>

---

# DataJoint Elements

https://github.com/datajoint/datajoint-elements

Notes: dont render
<Box width={"80%"} height={"80%"} margin={"auto"}>
  <Paper elevation={1} style={{width:"100%", height:"100%"}}>
    <iframe width={"100%"} height={"100%"}  loading={"lazy"}
            src={"https://github.com/datajoint/workflow-array-ephys"}
    />
  </Paper>
</Box>

---

# Federated P2P & Modular Analysis

* Replicability -- having a clearly reproducible analysis pipline is good
  in itself, but when the data sharing system is also designed
  such that someone doesn't need to set up a whole ass database,
  figure out how to get queries, it's even more dope.
* Inspectability - "never roll yr own crypto" but ppl roll their own
  analysis all day long. examples of bugs
* Scientific Consensus - giving a language to ongoing comparisons and
  debates in the field literally in their implementation allows
  us to more plainly see the diversity of opinion and results --
  what if you could apply an analysis method to an entire body of
  previously collected data? or two? This could decouple a paper from its analysis
* A Global F@H - At the point when everyone is connected
  and volunteering a million tiny servers, it would be possible to
  build a global folding@home with idle computing time datajoint
  elements says as much in their paper (screenshot)


---

# Experimental Framework

What do the next 10 years of neuroscience

experiments look like?

* **Infinitely variable** naturalistic experimental structure
* Complex, **multi-stage** and **continuous** tasks
* **Lots** of hardware
* Lots of **heterogeneous** hardware
* **Custom** and **off-the-shelf** hardware
* **All-To-All** control
* **Real-time** data processing
* **~Microsecond-precise** synchronization
* **High-Bandwidth** data collection
* **Multimodal** data collection


<Image src={ExptRequirements} style={{right:0, bottom:0,height:"80%", position:"absolute"}}></Image>

---


<Image src={Parallax} maxWidth={"100%"} maxHeight={"100%"}></Image>



Notes: Examples from Parallax task

* Describe the task (from nmc)
* IMU transformation example - lots of people need to do this, why is it so hard?
* Porting code is easy - adapted kalman filter & sensor code
* Having clear place to expand things
* Making each part of it separately available.
* Manipulating custom hardware is possible - video of platform
* Connecting separate components is possible
* Finish with DLC example

---

# Integrate with custom components

<div style={{"z-index": -1}}>
  <iframe loading={"lazy"}
          src="https://player.vimeo.com/video/543747956?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
          frameBorder="0" allow="autoplay; fullscreen; picture-in-picture" allowFullscreen
          style={{position: "absolute", top: 0, left: 0, width: "100%", height: "100%"}} title="hell_naw.mp4"></iframe>
</div><script src="https://player.vimeo.com/api/player.js"></script>

---

# Link in RT

<div style={{zIndex:-1}}>
  <iframe loading={"lazy"}
          src="https://player.vimeo.com/video/543748950?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
          frameBorder="0" allow="autoplay; fullscreen; picture-in-picture" allowFullscreen
          style={{position: "absolute", top: 0, left: 0, width: "100%", height: "100%"}}
          title="Motion Control"></iframe>
</div><script src="https://player.vimeo.com/api/player.js"></script>


---

# Combinatoric Benefits

* completely obviate the need for conversion
* Complete replication becomes possible -- circular provenance
* Making analytical tools

---

# Other projects

* Bonsai - good! we love it!
* BEADL - interesting! statecharts are cool! it's a big ask to
get everyone to fundamentally change how they express and
do their experiments, instead we should focus on the tool side
of thing rather than the standardization and formalization side
of things!!


---

# Again a design practice, not a product

We need to make our programs easier to interface with one another --
provide clearer inputs and outputs, points where other programs
can pull and push information to our programs.

BEADL this is a fundamentally diffrent approach to standardization
what if we made it unnecessary to standardize terminology and task definitions
by allowing people to express their task in their terms but in a
system where their contribution ould be integrated with others?

---

What's missing:

Community structure
